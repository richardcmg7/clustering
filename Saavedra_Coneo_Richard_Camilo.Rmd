---
title: "Actividad_3_AA_G10"
author: "Richard Saavedra"
date: "6/22/2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# install.packages("corrplot")
#install.packages("gmodels")
#install.packages("tidyverse")
#install.packages("readr")
#install.packages("caret")
#install.packages('Hmisc')
#install.packages("modeest") 

# install.packages("e1071")
# install.packages("caTools")
# install.packages("http://download.r-forge.r-project.org/src/contrib/IsolationForest_0.0-26.tar.gz", repo=NULL, type="source")
# install.packages("h2o")
# install.packages("dygraphs")
# install.packages("dplyr")
# install.packages("DT")


```

```{r warning=FALSE, results='hide', message=FALSE}
library( h2o )
library(caTools)
library(e1071)
library(gmodels)
library(caret)
library(tidyverse)
library(Hmisc)
library(modeest)
library(cluster)
library(corrplot)

```

### Se cargan los datos a la variable `data`

```{r}
set.seed(1234)
data <- read_csv("data/datos.csv")


```

Se revisa si existen valores nulos.

```{r}
str(data)
```
### Se hallan de las variables númericas el valor mínimo máximo, la mediana y la media.

Se hallan de las variables categoricas las diferentes categorias y la frecuencia de cada una de ellas.

Eliminamos la columna Transaction date que contiene todos los valores nulos.

```{r}
data$`Transaction date` <- NULL

```

Volver las columnas categoricas a númericas

```{r}
data$isFradulent <- as.factor(data$isFradulent)
data$isForeignTransaction <- as.factor(data$isForeignTransaction)
data$isHighRiskCountry <- as.factor(data$isHighRiskCountry)
data$`Is declined` <- as.factor(data$`Is declined`)
```

```{r}
summary(data)

```


Se cambian los valores que estaban en caracter de Y y N reeemplazandolos por 1 y 0 respectivamente

```{r}
data$isFradulent <- ifelse(data$isFradulent == "N",0,1)
data$`Is declined` <- ifelse(data$`Is declined` == "N",0,1)
data$isHighRiskCountry <- ifelse(data$isHighRiskCountry == "N",0,1)
data$isForeignTransaction<- ifelse(data$isForeignTransaction == "N",0,1)

str(data)
summary(data)
```

### Se hallan la correlaciones existentes entre las variables del conjunto de datos mediante la matriz de correlación

```{r}
corr <- cor(data[,])
corrGreater <- findCorrelation(corr, cutoff=0.8)
corrGreater
```

Se grafica la Matriz de correlación

```{r results="hide"}

Mat_Correlacion <- cor(data, method = "pearson")
round(Mat_Correlacion, digits = 2)
corrplot(Mat_Correlacion)

```

Se definen el conjunto de datos de modelización y validación

```{r}
train_data <- sample(nrow(data), 0.8 * nrow(data))
data_train <- data[train_data, ]
data_test <- data[-train_data, ]

```

```{r error=FALSE, message=FALSE, results='hide'}
h2o.init()
```

```{r}

allData_hex = as.h2o( data_train )
str(allData_hex)
```
Se aplica la tecnica de detección de anomalias h2o.isolationforest
```{r warning=FALSE}
dataModel = h2o.isolationForest( training_frame = allData_hex,
                                 x              = colnames(allData_hex)[-11],
                                 sample_rate    = 0.9,
                                 max_depth      = 100,
                                 ntrees         = 500
                                )
dataModel
```
Generamos la predicción

```{r results='hide', warning=FALSE}
allData_hex_test = as.h2o(data_test)
```

```{r warning=FALSE}
score = h2o.predict( dataModel, allData_hex_test )
result_pred = as.vector( score$predict )

```
```{r}



```

```{r}
predicciones_h2o <- h2o.predict(
                      object  = dataModel,
                      newdata = allData_hex
                    )
predicciones <- as.data.frame(predicciones_h2o)
predicciones
```
```{r}
library(ggplot2)
ggplot(data = predicciones, aes(x = mean_length)) +
  geom_histogram(color = "gray40") +
  geom_vline(
    xintercept = quantile(predicciones$mean_length, seq(0, 1, 0.1)),
    color      = "red",
    linetype   = "dashed") +
  labs(
    title = "Distribución de las distancias medias del Isolation Forest",
    subtitle = "Cuantiles marcados en rojo"  ) +
  theme_bw()
```

```{r}
cuantiles <- quantile(x = predicciones$mean_length, probs = seq(0, 1, 0.05))
cuantiles
```

```{r}

datos <- data_train %>%
         bind_cols(predicciones)
head(datos)

```
```{r}
  ggplot(data = datos,
         aes(x = isFradulent, y = mean_length)) +
  geom_jitter(aes(color = isFradulent), width = 0.03, alpha = 0.3) + 
  geom_violin(alpha = 0) +
  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0) +
  stat_summary(fun = "mean", colour = "orangered2", size = 3, geom = "point") +
  labs(title = "Distancia promedio en el modelo Isolation Forest",
       x = "clasificación (0 = normal, 1 = anomalía)",
       y = "Distancia promedio") +
  theme_bw() + 
  theme(legend.position = "none")
```

Acorde a la información del dataset, contiene 380 anomalías. Se muestra matriz de confusión resultante si se clasifican como anomalías las 380 observaciones con menor distancia predicha

```{r}
resultados <- datos %>%
              select(isFradulent, mean_length) %>%
              arrange(mean_length) %>%
              mutate(clasificacion = if_else(row_number() <= 380, "1", "0"))

```


```{r}
mat_confusion <- MLmetrics::ConfusionMatrix(
                    y_pred = resultados$clasificacion,
                    y_true = resultados$isFradulent
                 )
mat_confusion
```
Comentar sobre 
```{r}
a = 310 / 380 
falsos_positivos = 1 - a
falsos_positivos * 100
```


## Detección de Anomalias K-means

